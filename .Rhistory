library(tidyverse)   # covers ggplot2, dplyr, tidyr, readr, purrr, stringr
library(readxl)      # Excel input
library(writexl)     # Excel output
library(ggrepel)     # text repulsion in plots
library(drc)         # LOD modeling
library(ggpubr)      # publication-quality plots
library(strex)       # extra string utilities if you need them
### Data
std_curve_path="example standard curve.csv"
raw_data_path="example input/qPCR_results/"
metadata_path="example input/client_metadata_example.xlsx"
### Plots
std_curve_plot="example output/Standard_curve.png"
inhibition_plot="example output/Inhibition.png"
blanks_piechart="example output/Blanks_piechart.png"
field_samples_piechart="example output/Fields_piechart.png"
field_samples_barchart="example output/Fieldsamples_barchart.png"
outliers_plot="example output/Outliers.png"
### Results
results_blank="example output/Results_Blanks.xlsx"
results_samples="example output/Results.xlsx"
std_curve_raw <- read.csv(std_curve_path, skip = 19)
std_curve_raw %>% filter(Sample == "Neg")
std_curve <- std_curve_raw %>% dplyr::rename(St_Quant=8) %>%
## Remove NTCs
filter(!Sample == "Neg") %>%
## Calculate mean Cq
dplyr::group_by(Sample) %>%
mutate(Cq_mean = mean(Cq, na.rm=TRUE))
std_curve_raw %>% dplyr::rename(St_Quant=8) %>%
## Remove NTCs
filter(!Sample == "Neg")
std_curve_raw
std_curve <- std_curve_raw %>% dplyr::rename(St_Quant=7) %>%
## Remove NTCs
filter(!Sample == "Neg") %>%
## Calculate mean Cq
dplyr::group_by(Sample) %>%
mutate(Cq_mean = mean(Cq, na.rm=TRUE))
# Fit a linear model to calculate slope and intercept
linear_model <- lm(Cq_mean ~ log10(St_Quant), data = std_curve)
# Extract slope and y-intercept
slope <- coef(linear_model)[2]       # Slope (m)
y_intercept <- coef(linear_model)[1] # Y-intercept (b)
efficiency <- (-1+(10^(-1/slope)))
## Standard curve calculations (assuming std_curve is already grouped by Sample)
std_curve <- std_curve %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n(),
## calculate Cq stats - SD, and CV
Cq_sd = sd(Cq, na.rm=TRUE),
#Cq_cv = (Cq_sd / Cq_mean) * 100 ## old method
Cq_cv = sqrt(((1+efficiency) ^ ((Cq_sd^2) * log(1+efficiency))) - 1)) %>%
ungroup()
# Assuming std_curve is your data frame
quants <- std_curve %>% dplyr::select(St_Quant) %>% distinct() %>% arrange(desc(St_Quant))
# Creating a factored list of these standard curve values
quant_list <- as.factor(quants$St_Quant)
# Find the first value below the 0.95 detection rate
first_below_LOD_threshold <- std_curve %>% filter(detection_rate < 0.95) %>% arrange(desc(St_Quant)) %>%
slice(1) %>% dplyr::select(St_Quant)
# Get the standard quantity of the first value below the threshold
below_threshold_LOD_quant <- first_below_LOD_threshold$St_Quant[1]
# Find the index of this quantity in the ordered list
LOD_index <- which(quants$St_Quant == below_threshold_LOD_quant)
LOD <- quants$St_Quant[LOD_index - 1]
# Find the first value below the 0.35 CV
first_above_LOQ_threshold <- std_curve %>% filter(Cq_cv > 0.350) %>% arrange(desc(St_Quant)) %>%
slice(1) %>% dplyr::select(St_Quant)
# Get the standard quantity of the first value below the threshold
above_threshold_LOQ_quant <- first_above_LOQ_threshold$St_Quant[1]
# Find the index of this quantity in the ordered list
LOQ_index <- which(quants$St_Quant == above_threshold_LOQ_quant)
LOQ <- quants$St_Quant[LOQ_index - 1]
std_curve %>%
## Taking only those detections with >50% to make curve
filter(detection_rate > 0.50) %>%
## Plotting that std. curve
ggplot(., aes(x = log10(St_Quant), y = Cq)) +
geom_smooth(method = 'lm', se = FALSE, color = "darkred") +
stat_regline_equation(size = 4, color = 'darkred',
aes(label = after_stat(rr.label)), hjust=1,
label.x.npc = "right", label.y.npc = "top") +
geom_point(color = 'black', fill = 'white', shape = 21, size = 3.5, alpha=0.8) +
## ADDING LOD LINE -- if no line shows up, all st. curve is qualitative
geom_vline(xintercept=log10(LOD), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOD), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOD =", LOD, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
## ADDING LOQ LINE -- if no line shows up, all st. curve is quantitative
geom_vline(xintercept=log10(LOQ), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOQ), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOQ =", LOQ, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
theme_bw() +
labs(
x = "Normalized standard concentrations",
y = "Cq"
) +
theme(axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_text(size=10, color="grey20"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
ggsave(std_curve_plot, width=6, height=4)
### USER EDITS:
## In str_after_nth(file.ID, "results/", 1), make sure this matches the folder ending referenced in list.files
df <-
# list files in directory following a particular pattern
list.files(path = raw_data_path, pattern = ".csv", full.names = TRUE) %>%
# get the column names
set_names(.) %>%
# join all files together in one data frame by file ID, skipping first 19 rows
map_dfr(~read.csv(., skip = 19), .id = "file.ID") %>%
# turn file.ID into just plate information (plate.ID)
mutate(file.ID = str_after_nth(file.ID, "results/", 1),
file.ID = str_before_nth(file.ID, ".csv", 1)) %>%
dplyr::rename(plate.ID = file.ID, Sample_ID = Sample) %>%
#### HOLD SPACE FOR CUSTOM SAMPLE ID NEEDS,
##### IF NONE, COMMENT THIS SECTION OUT
## RI STRIPED BASS SPECIFIC CODE FOR SAMPLE ID MISMATCHES
mutate(Sample_ID = gsub(" #1", "_1", Sample_ID),
Sample_ID = gsub(" #2", "_2", Sample_ID)) %>%
mutate(Sample_ID = case_when(
str_detect(Well, "4") & Sample_ID == "2/21/24_ONE_NTR" ~ paste0(Sample_ID, "_1"),
str_detect(Well, "5") & Sample_ID == "2/21/24_ONE_NTR" ~ paste0(Sample_ID, "_2"),
TRUE ~ Sample_ID
)
##### #########################
)
head(df)
meta <- read_xlsx(metadata_path) %>%
#### HOLD SPACE FOR CUSTOM SAMPLE ID NEEDS,
##### IF NONE, COMMENT THIS SECTION OUT
## RI STRIPED BASS SPECIFIC CODE FOR SAMPLE ID ISSUES
## For other projects, address any Sample_ID differences (Sample_ID on qPCR output needs to match meta)
mutate(Sample_ID = gsub(" #1", "_1", Sample_ID),
Sample_ID = gsub(" #2", "_2", Sample_ID))
NTC <- df %>%
filter(grepl("neg", Sample_ID, ignore.case = TRUE))
## Calculate number of negatives with Cq values
sum(!is.na(NTC$Cq))
## Calculate number of negatives total
nrow(NTC)
## Calculate number of plates
length(unique(NTC$plate.ID))
spike_samples <- df %>%
## subset to spiked samples
filter(grepl("spike|pos", Sample_ID, ignore.case = TRUE)) %>%
## remove spike from SampleID column only if 'pos' is NOT in the Sample_ID
mutate(Sample_ID = case_when(
!grepl("pos", Sample_ID, ignore.case = TRUE) ~ str_before_nth(Sample_ID, " spike", 1),
TRUE ~ Sample_ID
)) %>%
## group by plate ID and sample ID
group_by(plate.ID, Sample_ID) %>%
## calculate mean of spikes per plate and sample
## ungroup by Sample_ID so the next calculation is only done grouped by Plate
mutate(Filter_Cq = mean(Cq)) %>%
ungroup(Sample_ID) %>%
## calculate difference from plate's Cq value
mutate(Cq_diff = Filter_Cq - Filter_Cq[grepl("pos", Sample_ID, ignore.case = TRUE)]) %>%
ungroup(); spike_samples
#### HOLD SPACE FOR CUSTOM SAMPLE ID NEEDS,
##### IF NONE, COMMENT THIS SECTION OUT
## Remove any lab error samples
## RI Striped Bass only
## removing 2/21/24 DI Blank 1 (pipetting issue)
spike_samples <- spike_samples %>%
filter(!Sample_ID == "2/21/24_Tap Blank_1")
# Create a jitter position object
jitter_pos <- position_jitter(width = 0.45, seed = 123)
## Plot samples
spike_samples %>% dplyr::select(Target, Sample_ID, Cq_diff) %>% distinct() %>%
ggplot(., aes(x=Target, y = Cq_diff)) +
geom_hline(yintercept = c(-2, 2), linetype = "dotted", color = "grey50", size=1.5) +
geom_jitter(aes(fill = abs(Cq_diff) > 2),
size = 2, alpha = 0.5, color = 'black', shape = 21, #width = 0.45,
position = jitter_pos) +
scale_fill_manual(values = c("TRUE" = "red", "FALSE" = "white")) +
geom_text_repel(
aes(label = ifelse(abs(Cq_diff) > 2, Sample_ID, "")),  position = jitter_pos,
size = 3, box.padding = 0.5, point.padding = 0.2, force = 2
) +
labs(
x = "Sample",
y = "Distance from Positive Control"
) +
theme_bw() +
## keep y axis at least -2,2 but extend to max
coord_cartesian(
ylim = c(
min(-2.5, min(spike_samples$Cq_diff, na.rm = TRUE)),
max(2.5, max(spike_samples$Cq_diff, na.rm = TRUE))
)) +
## theme variables
theme(panel.background=element_rect(fill='white', colour='black'),
legend.position = "none",
axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_blank(),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
ggsave(inhibition_plot, width=4, height=4)
## Complete calculations
filters_df <- df %>%
## subset out the spiked samples
filter(!grepl("spike|pos|neg", Sample_ID, ignore.case = TRUE)) %>%
## group by plate ID and sample ID
group_by(plate.ID, Sample_ID) %>%
## calculate mean of Cq per plate and sample, replacing NaN with NA
## calculate # of replicates
## calculate copy number
reframe(Filter_Cq = if_else(is.nan(mean(Cq, na.rm = TRUE)), NA_real_, mean(Cq, na.rm = TRUE)),
Filter_Num_Replicates = sum(!is.na(Cq)),
Filter_Copy_Num = 10^((Filter_Cq-y_intercept)/slope)
)
filters_df <- filters_df %>%
## Separating Plate.ID into Date and Plate Number
separate(plate.ID, c("Plate_date", "Plate_number"), sep = " PLATE") %>%
## Change Date column to a Date format
mutate(Plate_date = dmy(Plate_date)) %>%
## Group by Sample_ID and keep only the row with the most recent date
group_by(Sample_ID) %>%
slice_max(Plate_date, n = 1, with_ties = FALSE) %>% ungroup()
## confirm the number of rows matches the number of unique Sample IDs (output should be TRUE)
nrow(filters_df) == length(unique(filters_df$Sample_ID))
samples_df <- filters_df %>% right_join(meta, ., by = "Sample_ID") %>%
group_by(Date, Sample_Location) %>%
## mutate to mean Ct value
mutate(`Mean Ct` = if_else(is.nan(mean(Filter_Cq, na.rm = TRUE)),
NA_real_, mean(Filter_Cq, na.rm = TRUE)),
## take highest value of number of replicates
`Number of Replicates` = max(Filter_Num_Replicates, na.rm=TRUE),
## sum of 2 copy number values
`Mean Copy Number` = ifelse(sum(Filter_Copy_Num, na.rm=TRUE) == 0, NA,
sum(Filter_Copy_Num, na.rm=TRUE))
) %>%
ungroup() %>%
## summarizing df
dplyr::select(Date, Sample_Location, Sample_Type, Number_of_Filters,
`Mean Ct`, `Number of Replicates`, `Mean Copy Number`) %>%
distinct() %>%
## adding new SampleID back in
unite(Sample_ID, Date, Sample_Location, sep = " ", remove=F)
head(samples_df)
## Confirm that the number of samples output from qPCR matches the number of samples in the metadata (output = TRUE)
nrow(samples_df) == nrow(meta %>% dplyr::select(-Sample_ID) %>% distinct())
## normalize data
normalized_df <- samples_df %>%
## take log10 of copy number
mutate(`Mean Copy Number Normalized` = log10(`Mean Copy Number` + 1))
View(normalized_df)
### Identifying outliers
outliers <- normalized_df %>% dplyr::select(`Sample ID`, `Mean Copy Number Normalized`) %>%
mutate(
Median = median(`Mean Copy Number Normalized`),
MAD = mad(`Mean Copy Number Normalized`, constant=1),
Mi = 0.6745*(abs(`Mean Copy Number Normalized` - Median)/MAD),
Outlier = ifelse(Mi > 3.5, "Outlier", ""),
Upper_threshold = (3.5*MAD+0.6745*Median)/0.6745,
Lower_threshold =-1*(3.5*MAD-0.6745*Median)/0.6745
) %>%
arrange(desc(`Mean Copy Number Normalized`))
### Identifying outliers
outliers <- normalized_df %>% dplyr::select(`Sample_ID`, `Mean Copy Number Normalized`) %>%
mutate(
Median = median(`Mean Copy Number Normalized`),
MAD = mad(`Mean Copy Number Normalized`, constant=1),
Mi = 0.6745*(abs(`Mean Copy Number Normalized` - Median)/MAD),
Outlier = ifelse(Mi > 3.5, "Outlier", ""),
Upper_threshold = (3.5*MAD+0.6745*Median)/0.6745,
Lower_threshold =-1*(3.5*MAD-0.6745*Median)/0.6745
) %>%
arrange(desc(`Mean Copy Number Normalized`))
View(outliers)
unique(outliers$Upper_threshold)
