std_curve %>%
## Taking only those detections with >50% to make curve
filter(detection_rate > 0.50) %>%
## Plotting that std. curve
ggplot(., aes(x = log10(`Starting Quantity (SQ)`), y = Cq)) +
geom_smooth(method = 'lm', se = FALSE, color = "darkred") +
stat_regline_equation(size = 4, color = 'darkred',
aes(label = after_stat(rr.label)), hjust=1,
label.x.npc = "right", label.y.npc = "top") +
geom_point(color = 'black', fill = 'white', shape = 21, size = 3.5, alpha=0.8) +
## ADDING LOD LINE -- if no line shows up, all st. curve is qualitative
geom_vline(xintercept=log10(LOD_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOD_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOD =", LOD_threshold, " copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
## ADDING LOQ LINE -- if no line shows up, all st. curve is quantitative
geom_vline(xintercept=log10(LOQ_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOQ_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOQ =", LOQ_threshold, " copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
theme_bw() +
labs(
x = "Normalized standard concentrations",
y = "Cq"
) +
theme(axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_text(size=10, color="grey20"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
ggsave("example output/Standard_curve.png", width=6, height=4)
std_curve %>%
## Taking only those detections with >50% to make curve
filter(detection_rate > 0.50) %>%
## Plotting that std. curve
ggplot(., aes(x = log10(`Starting Quantity (SQ)`), y = Cq)) +
geom_smooth(method = 'lm', se = FALSE, color = "darkred") +
stat_regline_equation(size = 4, color = 'darkred',
aes(label = after_stat(rr.label)), hjust=1,
label.x.npc = "right", label.y.npc = "top") +
geom_point(color = 'black', fill = 'white', shape = 21, size = 3.5, alpha=0.8) +
## ADDING LOD LINE -- if no line shows up, all st. curve is qualitative
geom_vline(xintercept=log10(LOD_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOD_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOD =", LOD_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
## ADDING LOQ LINE -- if no line shows up, all st. curve is quantitative
geom_vline(xintercept=log10(LOQ_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOQ_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOQ =", LOQ_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
theme_bw() +
labs(
x = "Normalized standard concentrations",
y = "Cq"
) +
theme(axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_text(size=10, color="grey20"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
ggsave("example output/Standard_curve.png", width=6, height=4)
### USER EDITS:
## 1. Replace path of file with your own standard curve
std_curve <- read_xlsx("example standard curve.xlsx", skip = 19) %>%
group_by(Sample) %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n(),
## calculate Cq stats - mean, SD, and CV
Cq_mean = mean(Cq, na.rm=TRUE),
Cq_sd = sd(Cq, na.rm=TRUE),
Cq_cv = (Cq_sd / Cq_mean) * 100
) %>%
ungroup()
## confirming negatives were clean and filter them out
std_curve %>% filter(Sample == "neg")
std_curve <- std_curve %>% filter(!Sample == "neg")
LOD <- std_curve %>%
filter(detection_rate < 0.95) %>%      # Change the threshold as needed
slice(1) %>%                        # Get the first occurrence
select(Sample, detection_rate)      # Select relevant columns
LOD_threshold <- as.numeric(LOD$Sample[1])
LOQ <- std_curve %>%
filter(Cq_cv > 35.00) %>%      # Change the threshold as needed
slice(1) %>%                        # Get the first occurrence
select(Sample, Cq_cv)
LOQ_threshold <- as.numeric(LOQ$Sample[1])
std_curve %>%
## Taking only those detections with >50% to make curve
filter(detection_rate > 0.50) %>%
## Plotting that std. curve
ggplot(., aes(x = log10(`Starting Quantity (SQ)`), y = Cq)) +
geom_smooth(method = 'lm', se = FALSE, color = "darkred") +
stat_regline_equation(size = 4, color = 'darkred',
aes(label = after_stat(rr.label)), hjust=1,
label.x.npc = "right", label.y.npc = "top") +
geom_point(color = 'black', fill = 'white', shape = 21, size = 3.5, alpha=0.8) +
## ADDING LOD LINE -- if no line shows up, all st. curve is qualitative
geom_vline(xintercept=log10(LOD_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOD_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOD =", LOD_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
## ADDING LOQ LINE -- if no line shows up, all st. curve is quantitative
geom_vline(xintercept=log10(LOQ_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOQ_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOQ =", LOQ_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
theme_bw() +
labs(
x = "Normalized standard concentrations",
y = "Cq"
) +
theme(axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_text(size=10, color="grey20"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
ggsave("example output/Standard_curve.png", width=6, height=4)
# Fit a linear model to calculate slope and intercept
linear_model <- lm(Cq_mean ~ log10(`Starting Quantity (SQ)`), data = std_curve)
# Extract slope and y-intercept
slope <- coef(linear_model)[2]      # Slope (m)
y_intercept <- coef(linear_model)[1] # Y-intercept (b)
### USER EDITS:
## 1. Replace path of files
## 2. In str_after_nth(file.ID, "results/", 1), make sure this matches the folder ending referenced in list.files
df <-
# list files in directory following a particular pattern
list.files(path = 'example input/qPCR_results/', pattern = ".xlsx", full.names = TRUE) %>%
# get the column names
set_names(.) %>%
# join all files together in one data frame by file ID, skipping first 19 rows
map_dfr(~read_xlsx(., skip = 19), .id = "file.ID") %>%
# turn file.ID into just plate information (plate.ID)
mutate(file.ID = str_after_nth(file.ID, "results/", 1),
file.ID = str_before_nth(file.ID, ".xlsx", 1)) %>%
dplyr::rename(plate.ID = file.ID, Sample_ID = Sample) %>%
## RI STRIPED BASS SPECIFIC CODE FOR SAMPLE ID MISMATCHES
mutate(Sample_ID = gsub(" #1", "_1", Sample_ID),
Sample_ID = gsub(" #2", "_2", Sample_ID)) %>%
mutate(Sample_ID = case_when(
str_detect(Well, "4") & Sample_ID == "2/21/24_ONE_NTR" ~ paste0(Sample_ID, "_1"),
str_detect(Well, "5") & Sample_ID == "2/21/24_ONE_NTR" ~ paste0(Sample_ID, "_2"),
TRUE ~ Sample_ID
))
head(df)
meta <- read_xlsx("example input/client_metadata_example.xlsx") %>%
## RI STRIPED BASS SPECIFIC CODE FOR SAMPLE ID ISSUES
## For other projects, address any Sample_ID differences (Sample_ID on qPCR output needs to match meta)
mutate(Sample_ID = gsub(" #1", "_1", Sample_ID),
Sample_ID = gsub(" #2", "_2", Sample_ID))
NTC <- df %>%
filter(grepl("neg", Sample_ID, ignore.case = TRUE))
## Calculate number of negatives with Cq values
sum(!is.na(NTC$Cq))
## Calculate number of negatives total
nrow(NTC)
## Calculate number of plates
length(unique(NTC$plate.ID))
spike_samples <- df %>%
## subset to spiked samples
filter(grepl("spike|pos", Sample_ID, ignore.case = TRUE)) %>%
## remove spike from SampleID column only if 'pos' is NOT in the Sample_ID
mutate(Sample_ID = case_when(
!grepl("pos", Sample_ID, ignore.case = TRUE) ~ str_before_nth(Sample_ID, " spike", 1),
TRUE ~ Sample_ID
)) %>%
## group by plate ID and sample ID
group_by(plate.ID, Sample_ID) %>%
## calculate mean of spikes per plate and sample
## ungroup by Sample_ID so the next calculation is only done grouped by Plate
mutate(Filter_Cq = mean(Cq)) %>%
ungroup(Sample_ID) %>%
## calculate difference from plate's Cq value
mutate(Cq_diff = Filter_Cq - Filter_Cq[grepl("pos", Sample_ID, ignore.case = TRUE)]) %>%
ungroup(); spike_samples
## Remove any lab error samples
## RI Striped Bass only
## removing 2/21/24 DI Blank 1 (pipetting issue)
spike_samples <- spike_samples %>%
filter(!Sample_ID == "2/21/24_Tap Blank_1")
# Create a jitter position object
jitter_pos <- position_jitter(width = 0.45, seed = 123)
## Plot samples
spike_samples %>% dplyr::select(Target, Sample_ID, Cq_diff) %>% distinct() %>%
ggplot(., aes(x=Target, y = Cq_diff)) +
geom_hline(yintercept = c(-2, 2), linetype = "dotted", color = "grey50", size=1.5) +
geom_jitter(aes(fill = abs(Cq_diff) > 2),
size = 2, alpha = 0.5, color = 'black', shape = 21, #width = 0.45,
position = jitter_pos) +
scale_fill_manual(values = c("TRUE" = "red", "FALSE" = "white")) +
geom_text_repel(
aes(label = ifelse(abs(Cq_diff) > 2, Sample_ID, "")),  position = jitter_pos,
size = 3, box.padding = 0.5, point.padding = 0.2, force = 2
) +
labs(
x = "Sample",
y = "Distance from Positive Control"
) +
theme_bw() +
## keep y axis at least -2,2 but extend to max
coord_cartesian(
ylim = c(
min(-2.5, min(spike_samples$Cq_diff, na.rm = TRUE)),
max(2.5, max(spike_samples$Cq_diff, na.rm = TRUE))
)) +
## theme variables
theme(panel.background=element_rect(fill='white', colour='black'),
legend.position = "none",
axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_blank(),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
ggsave("example output/Inhibition.png", width=4, height=4)
## Complete calculations
filters_df <- df %>%
## subset out the spiked samples
filter(!grepl("spike|pos|neg", Sample_ID, ignore.case = TRUE)) %>%
## group by plate ID and sample ID
group_by(plate.ID, Sample_ID) %>%
## calculate mean of Cq per plate and sample, replacing NaN with NA
mutate(Filter_Cq = if_else(is.nan(mean(Cq, na.rm = TRUE)), NA_real_, mean(Cq, na.rm = TRUE))) %>%
## calculate # of replicates
mutate(Filter_Num_Replicates = sum(!is.na(Cq))) %>%
## calculate copy number
mutate(Filter_Copy_Num = 10^((Filter_Cq-y_intercept)/slope)) %>%
## summarize df with specific columns
dplyr::select(plate.ID, Sample_ID, Filter_Cq, Filter_Num_Replicates, Filter_Copy_Num) %>%
distinct() %>% ungroup()
filters_df <- filters_df %>%
## Separating Plate.ID into Date and Plate Number
separate(plate.ID, c("Plate_date", "Plate_number"), sep = " PLATE") %>%
## Change Date column to a Date format
mutate(Plate_date = dmy(Plate_date)) %>%
## Group by Sample_ID and keep only the row with the most recent date
group_by(Sample_ID) %>%
slice_max(Plate_date, n = 1, with_ties = FALSE) %>% ungroup()
## confirm the number of rows matches the number of unique Sample IDs (output should be TRUE)
nrow(filters_df) == length(unique(filters_df$Sample_ID))
samples_df <- filters_df %>% right_join(meta, ., by = "Sample_ID") %>%
group_by(Date, Sample_Location) %>%
## mutate to mean Ct value
mutate(`Mean Ct` = if_else(is.nan(mean(Filter_Cq, na.rm = TRUE)),
NA_real_, mean(Filter_Cq, na.rm = TRUE)),
## take highest value of number of replicates
`Number of Replicates` = max(Filter_Num_Replicates, na.rm=TRUE),
## sum of 2 copy number values
`Mean Copy Number` = ifelse(sum(Filter_Copy_Num, na.rm=TRUE) == 0, NA,
sum(Filter_Copy_Num, na.rm=TRUE))
) %>%
ungroup() %>%
## summarizing df
dplyr::select(Date, Sample_Location, Sample_Type, Number_of_Filters,
`Mean Ct`, `Number of Replicates`, `Mean Copy Number`) %>%
distinct() %>%
## adding new SampleID back in
unite(Sample_ID, Date, Sample_Location, sep = " ", remove=F)
head(samples_df)
## Confirm that the number of samples output from qPCR matches the number of samples in the metadata
nrow(samples_df) == nrow(meta %>% dplyr::select(-Sample_ID) %>% distinct())
## normalize data
normalized_df <- samples_df %>%
## take log10 of copy number
mutate(`Mean Copy Number Normalized` = log10(`Mean Copy Number` + 1))
## create an outlier cut-off
cutoff <- quantile(normalized_df$`Mean Copy Number Normalized`, na.rm = TRUE, probs=0.75) +
1.5*IQR(normalized_df$`Mean Copy Number Normalized`, na.rm=TRUE)
## create an outlier cut-off
cutoff_below <- quantile(normalized_df$`Mean Copy Number Normalized`, na.rm = TRUE, probs=0.25) -
1.5*IQR(normalized_df$`Mean Copy Number Normalized`, na.rm=TRUE)
## Output the values that outside the cutoff
normalized_df %>% filter(`Mean Copy Number Normalized` > cutoff)
normalized_df %>% filter(`Mean Copy Number Normalized` < cutoff_below)
## the cutoff we move forward with is the cutoff (high) but confirm no values are below the lower cutoff value
normalized_df <- normalized_df %>%
mutate(Detection = case_when(
is.na(`Mean Copy Number Normalized`) ~ "Absent",
TRUE ~ "Present"
))
LOD <- std_curve %>%
filter(detection_rate < 0.95) %>%      # Change the threshold as needed
slice(1) %>%                        # Get the first occurrence
select(Sample, detection_rate)      # Select relevant columns
LOD_threshold <- as.numeric(LOD$Sample[1])
LOQ <- std_curve %>%
filter(Cq_cv > 35.00) %>%      # Change the threshold as needed
slice(1) %>%                        # Get the first occurrence
select(Sample, Cq_cv)
LOQ_threshold <- as.numeric(LOQ$Sample[1])
### USER EDITS:
## 1. Replace path of file with your own standard curve
std_curve <- read_xlsx("example standard curve.xlsx", skip = 19) %>%
group_by(Sample) %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n(),
## calculate Cq stats - mean, SD, and CV
Cq_mean = mean(Cq, na.rm=TRUE),
Cq_sd = sd(Cq, na.rm=TRUE),
Cq_cv = (Cq_sd / Cq_mean) * 100
) %>%
ungroup()
## confirming negatives were clean and filter them out
std_curve %>% filter(Sample == "neg")
std_curve <- std_curve %>% filter(!Sample == "neg")
LOD <- std_curve %>%
filter(detection_rate < 0.95) %>%      # Change the threshold as needed
slice(1) %>%                        # Get the first occurrence
dplyr::select(Sample, detection_rate)      # Select relevant columns
LOD_threshold <- as.numeric(LOD$Sample[1])
LOQ <- std_curve %>%
filter(Cq_cv > 35.00) %>%      # Change the threshold as needed
slice(1) %>%                        # Get the first occurrence
dplyr::select(Sample, Cq_cv)
LOQ_threshold <- as.numeric(LOQ$Sample[1])
std_curve %>%
## Taking only those detections with >50% to make curve
filter(detection_rate > 0.50) %>%
## Plotting that std. curve
ggplot(., aes(x = log10(`Starting Quantity (SQ)`), y = Cq)) +
geom_smooth(method = 'lm', se = FALSE, color = "darkred") +
stat_regline_equation(size = 4, color = 'darkred',
aes(label = after_stat(rr.label)), hjust=1,
label.x.npc = "right", label.y.npc = "top") +
geom_point(color = 'black', fill = 'white', shape = 21, size = 3.5, alpha=0.8) +
## ADDING LOD LINE -- if no line shows up, all st. curve is qualitative
geom_vline(xintercept=log10(LOD_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOD_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOD =", LOD_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
## ADDING LOQ LINE -- if no line shows up, all st. curve is quantitative
geom_vline(xintercept=log10(LOQ_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOQ_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOQ =", LOQ_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
theme_bw() +
labs(
x = "Normalized standard concentrations",
y = "Cq"
) +
theme(axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_text(size=10, color="grey20"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
ggsave("example output/Standard_curve.png", width=6, height=4)
std_curve %>%
## Taking only those detections with >50% to make curve
filter(detection_rate > 0.50) %>%
## Plotting that std. curve
ggplot(., aes(x = log10(`Starting Quantity (SQ)`), y = Cq)) +
geom_smooth(method = 'lm', se = FALSE, color = "darkred") +
stat_regline_equation(size = 4, color = 'darkred',
aes(label = after_stat(rr.label)), hjust=1,
label.x.npc = "right", label.y.npc = "top") +
geom_point(color = 'black', fill = 'white', shape = 21, size = 3.5, alpha=0.8) +
## ADDING LOD LINE -- if no line shows up, all st. curve is qualitative
geom_vline(xintercept=log10(LOD_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOD_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOD =", LOD_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
## ADDING LOQ LINE -- if no line shows up, all st. curve is quantitative
geom_vline(xintercept=log10(LOQ_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOQ_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOQ =", LOQ_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
theme_bw() +
labs(
x = "Normalized standard concentrations",
y = "Cq"
) +
theme(axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_text(size=10, color="grey20"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
std_curve %>%
## Taking only those detections with >50% to make curve
filter(detection_rate > 0.50) %>%
## Plotting that std. curve
ggplot(., aes(x = log10(`Starting Quantity (SQ)`), y = Cq)) +
geom_smooth(method = 'lm', se = FALSE, color = "darkred") +
stat_regline_equation(size = 4, color = 'darkred',
aes(label = after_stat(rr.label)), hjust=1,
label.x.npc = "right", label.y.npc = "top") +
geom_point(color = 'black', fill = 'white', shape = 21, size = 3.5, alpha=0.8) +
## ADDING LOD LINE -- if no line shows up, all st. curve is qualitative
geom_vline(xintercept=log10(LOD_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOD_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOD =", LOD_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
## ADDING LOQ LINE -- if no line shows up, all st. curve is quantitative
geom_vline(xintercept=log10(LOQ_threshold), linetype="dashed", color = "grey40") +
geom_text(aes(x = log10(LOQ_threshold), y = max(std_curve$Cq, na.rm=TRUE) * 0.3,
label = paste("LOQ =", LOQ_threshold, "copies")),
angle = 90, vjust = -0.5, hjust = -0.1, color = "grey40", size = 4) +
theme_bw() +
labs(
x = "Normalized standard concentrations",
y = "Cq"
) +
theme(axis.text.y = element_text(size=10, color="grey20"),
axis.text.x = element_text(size=10, color="grey20"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=12, face="bold"),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0), size=12, face="bold"))
library(ggplot2) ## for plotting
library(tidyverse) ## for data table manipulation
library(readr) ## for reading in tsv files
library(readxl) ## for reading in excel files
library(stringr) ## for data transformation
library(strex) ## for data transformation
library(writexl) ## for excel output
library(purrr) ## for data transformation
library(ggrepel)  ## For geom_text_repel
library(drc) ## for LOD calculations
library(ggpubr)
### USER EDITS:
## 1. Replace path of file with your own standard curve
std_curve <- read.csv("example standard curve.csv", skip = 19) %>% dplyr::rename(St_Quant=7) %>%
## Calculate mean Cq
dplyr::group_by(Sample) %>%
mutate(Cq_mean = mean(Cq, na.rm=TRUE))
View(std_curve)
# Fit a linear model to calculate slope and intercept
linear_model <- lm(Cq_mean ~ log10(St_Quant), data = std_curve)
# Extract slope and y-intercept
slope <- coef(linear_model)[2]       # Slope (m)
y_intercept <- coef(linear_model)[1] # Y-intercept (b)
std_curve %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n()
std_curve
std_curve %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n(),
## calculate E as qPCR efficiency Efficiency=−1+10^(−1/Slope)
E = (-1+(10^(-1/slope))))
efficiency <- (-1+(10^(-1/slope))))
efficiency <- (-1+(10^(-1/slope)))
slope
(-1/slope)
10^(-1/slope)
sd(Cq_mean)
### USER EDITS:
## 1. Replace path of file with your own standard curve
std_curve <- read.csv("example standard curve.csv", skip = 19) %>% dplyr::rename(St_Quant=7) %>%
## Calculate mean Cq
dplyr::group_by(Sample) %>%
mutate(Cq_mean = mean(Cq, na.rm=TRUE))
sd(std_curve$Cq_mean)
# Fit a linear model to calculate slope and intercept
linear_model <- lm(Cq_mean ~ log10(St_Quant), data = std_curve)
# Extract slope and y-intercept
slope <- coef(linear_model)[2]       # Slope (m)
y_intercept <- coef(linear_model)[1] # Y-intercept (b)
efficiency <- (-1+(10^(-1/slope)))
## Standard curve calculations (assuming std_curve is already grouped by Sample)
std_curve <- std_curve %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n(),
## calculate Cq stats - SD, and CV
Cq_sd = sd(Cq, na.rm=TRUE),
#Cq_cv = (Cq_sd / Cq_mean) * 100 ## old method
Cq_cv = sqrt(((1+efficiency) ^ ((Cq_sd^2) * ln(1+efficiency))) - 1)
) %>%
ungroup()
# Fit a linear model to calculate slope and intercept
linear_model <- lm(Cq_mean ~ log10(St_Quant), data = std_curve)
# Extract slope and y-intercept
slope <- coef(linear_model)[2]       # Slope (m)
y_intercept <- coef(linear_model)[1] # Y-intercept (b)
efficiency <- (-1+(10^(-1/slope)))
## Standard curve calculations (assuming std_curve is already grouped by Sample)
std_curve <- std_curve %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n(),
## calculate Cq stats - SD, and CV
Cq_sd = sd(Cq, na.rm=TRUE),
#Cq_cv = (Cq_sd / Cq_mean) * 100 ## old method
Cq_cv = sqrt(((1+efficiency) ^ ((Cq_sd^2) * ln(1+efficiency))) - 1)) %>%
ungroup()
# Fit a linear model to calculate slope and intercept
linear_model <- lm(Cq_mean ~ log10(St_Quant), data = std_curve)
# Extract slope and y-intercept
slope <- coef(linear_model)[2]       # Slope (m)
y_intercept <- coef(linear_model)[1] # Y-intercept (b)
efficiency <- (-1+(10^(-1/slope)))
## Standard curve calculations (assuming std_curve is already grouped by Sample)
std_curve <- std_curve %>%
## calculate detection rates (number of Cqs present / number of replicates)
mutate(detection_rate = sum(!is.na(Cq)) / n(),
## calculate Cq stats - SD, and CV
Cq_sd = sd(Cq, na.rm=TRUE),
#Cq_cv = (Cq_sd / Cq_mean) * 100 ## old method
Cq_cv = sqrt(((1+efficiency) ^ ((Cq_sd^2) * log(1+efficiency))) - 1)) %>%
ungroup()
std_curve %>% filter(Sample == "neg")
std_curve <- std_curve %>% filter(!Sample == "neg")
LOD <- std_curve %>%
filter(detection_rate < 0.95) %>%      # Change the threshold as needed
slice(1) %>%                        # Get the first occurrence
dplyr::select(Sample, detection_rate)      # Select relevant columns
LOD
std_curve %>%
filter(detection_rate < 0.95)
quants <- as.factor(std_curve$Sample)
quants
quants <- as.factor(std_curve %>% dplyr::select(Sample) %>% distinct())
std_curve %>% dplyr::select(Sample) %>% distinct()
std_curve %>% dplyr::select(St_Quant)
std_curve %>% dplyr::select(St_Quant) %>% distinct()
std_curve %>% dplyr::select(St_Quant) %>% distinct() %>% arrange()
std_curve %>% dplyr::select(St_Quant) %>% distinct() %>% arrange(desc(St_Quant))
quants <- as.factor(std_curve %>% dplyr::select(St_Quant) %>% distinct() %>% arrange(desc(St_Quant)))
quants <- std_curve %>% dplyr::select(St_Quant) %>% distinct() %>% arrange(desc(St_Quant))
quants
quant_list <- as.factor(quants$St_Quant)
quant_list
